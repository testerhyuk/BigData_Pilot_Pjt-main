(Server02에서 root로 진행)

1. Hue의 하이브쿼리 에서 스마트카 마스터정보를 조회하여 로컬 디스크에 저장한다
insert overwrite local directory '/home/pilot-pjt/mahout-data/clustering/input'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ' '
select 
  car_number,
  case 
      when (car_capacity < 2000) then '소형'
      when (car_capacity < 3000) then '중형'
      when (car_capacity < 4000) then '대형'
  end as car_capacity,
  case
      when ((2016-car_year) <= 4)  then 'NEW' 
      when ((2016-car_year) <= 8)  then 'NORMAL' 
      else 'OLD'
  end as car_year ,
  car_model,
  sex as owner_sex,
  floor (cast(age as int) * 0.1 ) * 10 as owner_age,
  marriage as owner_marriage,
  job as owner_job,
  region as owner_region
from smartcar_master

2. 내용확인
$ more /home/pilot-pjt/mahout-data/clustering/input/*

3. 로컬저장소에 저장된 000000_0을 smartcar_master.txt로 바꾸고 hdfs 경로 내에 넣는다
$ hdfs dfs -mkdir -p /pilot-pjt/mahout/clustering/input
$ cd /home/pilot-pjt/mahout-data/clustering/input
$ mv 000000_0 smartcar_master.txt
$ hdfs dfs -put smartcar_master.txt /pilot-pjt/mahout/clustering/input

4. FileZilla에서 mahout-data를 /home/pilot-pjt/mahout-data 경로로 업데이트
(머하웃의 Canopy 분석은 원천 파일이 시퀀스  파일이어야 가능함)

5. 텍스트 형식의 "스마트카 사용자 마스터" 파일을 시퀀스 파일로 변환한다.
$ hadoop jar /home/pilot-pjt/mahout-data/bigdata.smartcar.mahout-1.0.jar com.wikibook.bigdata.smartcar.mahout.TextToSequence /pilot-pjt/mahout/clustering/input/smartcar_master.txt /pilot-pjt/mahout/clustering/output/seq
$ hdfs dfs -text /pilot-pjt/mahout/clustering/output/seq/part-m-00000

6. 해당 시퀀스 파일을 로우별(차량번호)로 n-gram 기반의 TF(Term Frequency) 가중치가 반영된 벡터 데이터로 변환
$ mahout seq2sparse -i /pilot-pjt/mahout/clustering/output/seq -o /pilot-pjt/mahout/clustering/output/vec -wt tf -s 5 -md 3 -ng 2 -x 85 --namedVector
# wt : 단어 빈도 가중치 방식
# md : 최소 문서 출현 횟수
# ng : ngrams 최댓값
# namedVector : 네임벡터 데이터 생성

7. Canopy 군집분석
$ mahout canopy -i /pilot-pjt/mahout/clustering/output/vec/tf-vectors/ -o /pilot-pjt/mahout/clustering/canopy/out -dm org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure -t1 50 -t2 45 -ow
# i : 벡터 파일 경로
# o : 출력 결과 경로
# dm : 군집 거리 측정 알고리즘
# t1 : 거리값 1
# t2 : 거리값 2

8. 군집분석 결과
$ mahout clusterdump -i /pilot-pjt/mahout/clustering/canopy/out/clusters-*-final

9. t1, t2의 값을 각각 10, 8으로 설정
$ mahout canopy -i /pilot-pjt/mahout/clustering/output/vec/tf-vectors/ -o /pilot-pjt/mahout/clustering/canopy/out -dm org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure -t1 10 -t2 8 -ow
$ mahout clusterdump -i /pilot-pjt/mahout/clustering/canopy/out/clusters-*-final

10. t1, t2의 값을 각각 12, 10으로 설정
$ mahout canopy -i /pilot-pjt/mahout/clustering/output/vec/tf-vectors/ -o /pilot-pjt/mahout/clustering/canopy/out -dm org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure -t1 12 -t2 10 -ow
$ mahout clusterdump -i /pilot-pjt/mahout/clustering/canopy/out/clusters-*-final

11. Canopy 군집분석에서 나온 클러스터 수를 참고해서 다음 진행할 K-means 군집의 K값을 더욱 늘려본다
$ zeppelin-daemon.sh start # 재플린실행
[Notebook]
-> [Create new note]
-> [Note name] : "SmartCar-Clustering"
-> [Default Interpreter] : "spark"

12. 
//그림 7.96 스파크ML 라이브러리 임포트--------------------------------------------------------------

import org.apache.spark.ml.feature.MinMaxScaler
import org.apache.spark.ml.feature.StringIndexer
import org.apache.spark.ml.clustering.KMeansModel
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.clustering.KMeans
import org.apache.spark.ml.evaluation.ClusteringEvaluator

//그림 7.97 스마트카 마스터 데이터셋 로드--------------------------------------------------------------

val ds = spark.read.option("delimiter", " ")
                   .csv("/pilot-pjt/mahout/clustering/input/smartcar_master.txt")
ds.show(5)

//그림 7.98 스마트카 마스터 데이터셋 재구성--------------------------------------------------------------

val dsSmartCar_Master_1 = ds.selectExpr(
                        "cast(_c0 as string) car_number",
                        "cast(_c1 as string) car_capacity",
                        "cast(_c2 as string) car_year",
                        "cast(_c3 as string) car_model",
                        "cast(_c4 as string) sex",
                        "cast(_c5 as string) age",
                        "cast(_c6 as string) marriage",
                        "cast(_c7 as string) job",
                        "cast(_c8 as string) region"
                       )

//그림 7.99 문자형 칼럼을 연속형(숫자형) 칼럼으로 변환 및 생성--------------------------------------------------------------


val dsSmartCar_Master_2 = new StringIndexer().setInputCol("car_capacity").setOutputCol("car_capacity_n")
                                             .fit(dsSmartCar_Master_1).transform(dsSmartCar_Master_1)
val dsSmartCar_Master_3 = new StringIndexer().setInputCol("car_year").setOutputCol("car_year_n")
                                             .fit(dsSmartCar_Master_2).transform(dsSmartCar_Master_2)
val dsSmartCar_Master_4 = new StringIndexer().setInputCol("car_model").setOutputCol("car_model_n")
                                             .fit(dsSmartCar_Master_3).transform(dsSmartCar_Master_3)
val dsSmartCar_Master_5 = new StringIndexer().setInputCol("sex").setOutputCol("sex_n")
                                             .fit(dsSmartCar_Master_4).transform(dsSmartCar_Master_4)
val dsSmartCar_Master_6 = new StringIndexer().setInputCol("age").setOutputCol("age_n")
                                             .fit(dsSmartCar_Master_5).transform(dsSmartCar_Master_5)
val dsSmartCar_Master_7 = new StringIndexer().setInputCol("marriage").setOutputCol("marriage_n")
                                             .fit(dsSmartCar_Master_6).transform(dsSmartCar_Master_6)
val dsSmartCar_Master_8 = new StringIndexer().setInputCol("job").setOutputCol("job_n")
                                             .fit(dsSmartCar_Master_7).transform(dsSmartCar_Master_7)
val dsSmartCar_Master_9 = new StringIndexer().setInputCol("region").setOutputCol("region_n")
                                             .fit(dsSmartCar_Master_8).transform(dsSmartCar_Master_8)


//그림 7.100 클러스터링에 사용할 피처 변수 선택--------------------------------------------------------------

val cols = Array("car_capacity_n", "car_year_n", "car_model_n", "sex_n", "marriage_n")

val dsSmartCar_Master_10 = new VectorAssembler().setInputCols(cols).setOutputCol("features")
                                                .transform(dsSmartCar_Master_9)
val dsSmartCar_Master_11 = new MinMaxScaler().setInputCol("features").setOutputCol("scaledFeatures")
                                             .fit(dsSmartCar_Master_10).transform(dsSmartCar_Master_10)

//그림 7.101 스마트카 마스터 데이터셋 확인 및 학습/검증 데이터 생성----------------------------------------------


val dsSmartCar_Master_12 = dsSmartCar_Master_11.drop("car_capacity").drop("car_year").drop("car_model").drop("sex")
                                               .drop("age").drop("marriage").drop("job").drop("region").drop("features")
                                               .withColumnRenamed("scaledfeatures", "features")
dsSmartCar_Master_12.show(5)                                               

val Array(trainingData, testData) = dsSmartCar_Master_12.randomSplit(Array(0.7, 0.3))

//그림 7.102 스파크ML에서의 K-Means 군집 분석 실행--------------------------------------------------------------


val kmeans = new KMeans()
  .setSeed(1L)
  .setK(200)
  .setFeaturesCol("features")
  .setPredictionCol("prediction")
val kmeansModel = kmeans.fit(dsSmartCar_Master_12)


//그림 7.103 스파크ML에서의 K-Means 군집 결과 확인--------------------------------------------------------------


val transKmeansModel = kmeansModel.transform(dsSmartCar_Master_12)
transKmeansModel.groupBy("prediction").agg(collect_set("car_number").as("car_number")).orderBy("prediction").show(200, false)


//그림 7.104 스파크ML에서의 K-Means 군집 모델 평가 – 실루엣 스코어--------------------------------------------------------------

val evaluator = new ClusteringEvaluator()
val silhouette = evaluator.evaluate(transKmeansModel)

println(s"Silhouette Score = $silhouette")

